{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Conditional GAN for creating random handwritten digits\n",
    "This notebook trains a conditional GAN which is able to generate handwirtten digits using the MNIST dataset. This notebook is inspired by [this](https://medium.com/towards-data-science/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0) blog post.\n",
    "\n",
    "#### Speed\n",
    "On Tesla K80 with batch size of 256 and 2000 iterations, the speed is about 1.4it/s and training takes about 23 minutes (TensorFlow backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D, Flatten, Dropout, Dense, UpSampling2D, Reshape\n",
    "from keras.layers import Conv2DTranspose, Activation, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from tqdm import tnrange\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset consists of 28x28 grayscale images\n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "channel = 3\n",
    "\n",
    "classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = 64\n",
    "dropout = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                90123     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 4,396,683\n",
      "Trainable params: 4,396,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "input_shape = (img_rows, img_cols, channel)\n",
    "\n",
    "discriminator.add(Conv2D(depth*1, 5, strides=2, \n",
    "                         input_shape=input_shape,padding='same'))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(dropout))\n",
    "\n",
    "discriminator.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(dropout))\n",
    "\n",
    "discriminator.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(dropout))\n",
    "\n",
    "discriminator.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dropout(dropout))\n",
    "\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(classes + 1))\n",
    "discriminator.add(Activation('softmax'))\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
    "\n",
    "discriminator_model = Sequential()\n",
    "discriminator_model.add(discriminator)\n",
    "\n",
    "discriminator_model.compile(loss='categorical_crossentropy', \n",
    "                            optimizer=optimizer, \n",
    "                            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout = 0.4\n",
    "depth = 64+64+64+64\n",
    "dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 16384)             1818624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 3)         4803      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 2,913,923\n",
      "Trainable params: 2,880,771\n",
      "Non-trainable params: 33,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = Sequential()\n",
    "\n",
    "generator.add(Dense(dim*dim*depth, input_dim=100 + classes))\n",
    "generator.add(BatchNormalization(momentum=0.9))\n",
    "generator.add(Activation('relu'))\n",
    "generator.add(Reshape((dim, dim, depth)))\n",
    "generator.add(Dropout(dropout))\n",
    "\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=0.9))\n",
    "generator.add(Activation('relu'))\n",
    "\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "generator.add(BatchNormalization(momentum=0.9))\n",
    "generator.add(Activation('relu'))\n",
    "\n",
    "generator.add(Conv2DTranspose(3, 5, padding='same'))\n",
    "generator.add(Activation('sigmoid'))\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Adverserial\n",
    "The adversarial model is build by combining both the discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_3 (Sequential)    (None, 32, 32, 3)         2913923   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 11)                4396683   \n",
      "=================================================================\n",
      "Total params: 7,310,606\n",
      "Trainable params: 2,880,771\n",
      "Non-trainable params: 4,429,835\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "\n",
    "adversarial_model = Sequential()\n",
    "adversarial_model.add(generator)\n",
    "discriminator.trainable = False\n",
    "adversarial_model.add(discriminator)\n",
    "\n",
    "adversarial_model.compile(loss='categorical_crossentropy', \n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "adversarial_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = np.concatenate((x_train, x_test))\n",
    "y_train = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images):\n",
    "    images=images.astype('float32')\n",
    "    if images.max() > 1.0:\n",
    "        images/=255.0\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels):\n",
    "    enc = OneHotEncoder()\n",
    "    return enc.fit_transform(y_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train)\n",
    "y_train = one_hot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create random noise and concatenate it with random class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_generator_noise(batch_size):\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "    sampling = np.random.randint(classes, size=batch_size)\n",
    "    noise_labels = np.zeros((batch_size, classes))\n",
    "    noise_labels[np.arange(batch_size), sampling] = 1\n",
    "    noise_input = np.concatenate((noise, noise_labels), axis=1)\n",
    "    \n",
    "    return noise_input, noise_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_generator_noise_by_label(labels):\n",
    "    noise = np.random.uniform(-1.0, 1.0, size=[len(labels), 100])\n",
    "\n",
    "    noise_labels = np.zeros((len(labels), classes))\n",
    "    noise_labels[np.arange(len(labels)), labels] = 1\n",
    "    noise_input = np.concatenate((noise, noise_labels), axis=1)\n",
    "    \n",
    "    return noise_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(batch_size=256, train_steps=2000):\n",
    "    discriminator_losses = []\n",
    "    adversarial_losses = []\n",
    "    sample_images = []\n",
    "    \n",
    "    for i in tnrange(train_steps):\n",
    "        # Select a random sample from the training data and the labels\n",
    "        sample_idx = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
    "        images_train = x_train[sample_idx, :, :, :]\n",
    "        labels_train = y_train[sample_idx]\n",
    "        labels_train = np.concatenate((labels_train, np.zeros(shape=(batch_size, 1))), axis=1)\n",
    "        \n",
    "        # Create noise in range -1 to 1 and random labels as input for the generator to generate the fake images\n",
    "        noise_input, _ = create_generator_noise(batch_size)\n",
    "        images_fake = generator.predict(noise_input)\n",
    "        \n",
    "        # Create input by concatenate both real and fake images and assigning the respective labels\n",
    "        labels_fake = np.zeros(shape=(batch_size, classes+1))\n",
    "        labels_fake[:,-1] = 1\n",
    "        \n",
    "        input_data   = np.concatenate((images_train, images_fake))\n",
    "        input_labels = np.concatenate((labels_train, labels_fake))\n",
    "\n",
    "        discriminator_loss = discriminator_model.train_on_batch(input_data, input_labels)\n",
    "        \n",
    "        # Train the adversarial model to generate better images\n",
    "        noise_input, noise_labels = create_generator_noise(batch_size)\n",
    "        noise_labels = np.concatenate((noise_labels, np.zeros(shape=(batch_size, 1))), axis=1)\n",
    "        \n",
    "        adversarial_loss = adversarial_model.train_on_batch(noise_input, noise_labels)\n",
    "        \n",
    "        discriminator_losses.append(discriminator_loss)\n",
    "        adversarial_losses.append(adversarial_loss)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            labels = [1]\n",
    "            noise = create_generator_noise_by_label(labels)\n",
    "            fake_images = generator.predict(noise)\n",
    "            sample_images.append(fake_images[0])\n",
    "    \n",
    "    return discriminator_losses, adversarial_losses, sample_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91ddb820a564033a53877c5de04573f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discriminator_losses, adversarial_losses, sample_images  = train(train_steps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i, fake_image in enumerate(sample_images, 0):\n",
    "    plt.subplot(20, 10, i+1)\n",
    "    plt.imshow(np.reshape(fake_image, (img_cols, img_rows, channel)), cmap='gray')\n",
    "    plt.title(\"Iteration %d\" % (i * 100))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(np.array(discriminator_losses)[:, 0])\n",
    "plt.title(\"Discriminator Losses\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(np.array(discriminator_losses)[:, 1])\n",
    "plt.title(\"Discriminator Accuracy\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(np.array(adversarial_losses)[:, 0], color='darkorange')\n",
    "plt.title(\"Adveserial Losses\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(np.array(adversarial_losses)[:, 1], color='darkorange')\n",
    "plt.title(\"Adveserial Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Images given Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [5, 4, 2, 6, 1, 2, 2, 9, 8, 3]\n",
    "noise = create_generator_noise_by_label(labels)\n",
    "\n",
    "fake_images = generator.predict(noise)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i, fake_image in enumerate(fake_images, 1):\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(np.reshape(fake_image, (img_cols, img_rows, channel)), cmap='gray')\n",
    "    plt.title(labels[i-1])\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0c84ce278a6c49ddb1719d6e2082a3ce": {
     "views": []
    },
    "178bb74907ca4a4ba5b371f141e23fc7": {
     "views": []
    },
    "18eb0317c861477a8c69d09451980b45": {
     "views": []
    },
    "2e19d1896d454128a61adcc925a44e89": {
     "views": []
    },
    "31ea4d0ceb1f478caaa20f65adffee9a": {
     "views": []
    },
    "328f73774e004fdaa8e71a414bf8960e": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "69549b82d6ca445fba54f2224baaf480": {
     "views": []
    },
    "88210d7ae97e474d8be1106bc1075aef": {
     "views": []
    },
    "a1c6b0f011c34ae1947815fdb5fbbf17": {
     "views": []
    },
    "b2b885e77b1941449bced0562cabe61b": {
     "views": []
    },
    "b9cdf7ea9f0843a2ab31f9df3dff0542": {
     "views": []
    },
    "f91beb0a7a174ae39fd13f5e6cb0c320": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
